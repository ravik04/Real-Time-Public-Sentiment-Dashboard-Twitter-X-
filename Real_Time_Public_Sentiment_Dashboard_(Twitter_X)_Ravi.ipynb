{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzedgI4t/F3hqmbYZeJaH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravik04/Real-Time-Public-Sentiment-Dashboard-Twitter-X-/blob/main/Real_Time_Public_Sentiment_Dashboard_(Twitter_X)_Ravi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddHCtkPq0yFh"
      },
      "outputs": [],
      "source": [
        "pip install tweepy nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import time\n",
        "\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAMw21wEAAAAAC%2BNE00Bwvc2agGF7heh13zJ3THU%3D4clx3F7u4QpSbB5tJblDUKkaJgrGRmbx2OwEE7p7EuinwiAMGu\"\n",
        "\n",
        "client = tweepy.Client(bearer_token=bearer_token)\n",
        "\n",
        "user_input = input(\"Enter a keyword to search for: \")\n",
        "\n",
        "# Search for recent tweets mentioning a keyword (last 7 days)\n",
        "query = f\"{user_input} -is:retweet lang:en\"\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "try:\n",
        "    response = client.search_recent_tweets(query=query, max_results=100, tweet_fields=['created_at', 'text'])\n",
        "except tweepy.TooManyRequests:\n",
        "    print(\"Rate limit hit. Waiting 15 minutes...\")\n",
        "    time.sleep(15 * 60)  # sleep 15 minutes\n",
        "\n",
        "\n",
        "if response.data:\n",
        "    for tweet in response.data:\n",
        "        print(f\"{tweet.created_at} - {tweet.text}\")\n",
        "else:\n",
        "    print(\"No tweets found.\")\n"
      ],
      "metadata": {
        "id": "CZDYDJ6ZGc1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download the VADER sentiment lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "79TPMKRflUPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility functions for cleaning and sentiment analysis\n",
        "def clean_tweet(text):\n",
        "    return text.replace('\\n', ' ').strip()\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    score = sia.polarity_scores(text)['compound']\n",
        "    if score >= 0.05:\n",
        "        return 'Positive', score\n",
        "    elif score <= -0.05:\n",
        "        return 'Negative', score\n",
        "    else:\n",
        "        return 'Neutral', score\n"
      ],
      "metadata": {
        "id": "z7fmEVmGknNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets_data = []\n",
        "\n",
        "if response.data:\n",
        "    for tweet in response.data:\n",
        "        cleaned = clean_tweet(tweet.text)\n",
        "        sentiment, score = analyze_sentiment(cleaned)\n",
        "        tweets_data.append({\n",
        "            'id': tweet.id,\n",
        "            'Time': tweet.created_at,\n",
        "            'Tweet': cleaned,\n",
        "            'Sentiment': sentiment,\n",
        "            'Score': score\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(tweets_data)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mv8BNpAulVHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "A54lIR0mmPDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"tweet_sentiment_output.csv\", index=False)\n",
        "print(\"Data exported to tweet_sentiment_output.csv\")"
      ],
      "metadata": {
        "id": "F_Mmg7bxmfl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot sentiment distribution\n",
        "sns.countplot(data=df, x='Sentiment', palette='Set2')\n",
        "plt.title(f\"Sentiment Distribution for '{user_input}'\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Number of Tweets\")\n",
        "plt.show()\n",
        "\n",
        "# Optional: Time-series plot of sentiment scores\n",
        "df['Time'] = pd.to_datetime(df['Time'])\n",
        "df.sort_values('Time', inplace=True)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=df, x='Time', y='Score', label='Sentiment Score')\n",
        "plt.title(f\"Sentiment Score Trend for '{user_input}'\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Compound Sentiment Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VDnK_9Q1wbSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "filename = 'daily_sentiment_log.csv'\n",
        "file_exists = os.path.isfile(filename)\n",
        "\n",
        "df.to_csv(filename, mode='a', header=not file_exists, index=False)\n",
        "print(f\"Data appended to {filename}\")"
      ],
      "metadata": {
        "id": "F6LHLNE7woy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}